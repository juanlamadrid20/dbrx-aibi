{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f80dc12a-92d8-4e0e-b4a7-8f57f7b40681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# System Tables\n",
    "- https://docs.databricks.com/en/admin/system-tables/index.html\n",
    "- https://docs.databricks.com/en/admin/system-tables/billing.html\n",
    "- https://docs.databricks.com/en/admin/system-tables/compute.html\n",
    "\n",
    "# Run\n",
    "- This notebook is entirelly sql; rec'd running against serverless sql warehouse for best experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a218d068-838a-4436-9461-854f76d7c0bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- DBUs by cluster\n",
    "SELECT\n",
    "  usage_date,\n",
    "  sku_name,\n",
    "  usage_metadata.cluster_id,\n",
    "  SUM(usage_quantity) as total_dbu\n",
    "FROM \n",
    "  system.billing.usage\n",
    "WHERE \n",
    "  usage_metadata.cluster_id IN ('1216-145612-m94k4ybw')\n",
    "  and usage_date >= DATEADD(day, -30, current_date)\n",
    "  -- AND usage_unit = 'DBUs'\n",
    "GROUP BY ALL\n",
    "ORDER BY \n",
    "  usage_date DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62f89adf-d79d-4ab4-bdae-43ebda01c404",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ganglia sytle metrics, e.g. CPU, Memory, Disk, Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "751674ad-85dd-4f90-bf7d-077d73d6e17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- simple example\n",
    "SELECT \n",
    "  cluster_id,\n",
    "  instance_id,\n",
    "  start_time,\n",
    "  end_time,\n",
    "  ROUND(cpu_user_percent + cpu_system_percent + cpu_wait_percent, 2) as total_cpu_percent,\n",
    "  ROUND(mem_used_percent, 2) as memory_used_percent,\n",
    "  ROUND(network_received_bytes/1024/1024, 2) as network_received_mb,\n",
    "  ROUND(network_sent_bytes/1024/1024, 2) as network_sent_mb\n",
    "FROM system.compute.node_timeline\n",
    "WHERE cluster_id = '1216-145612-m94k4ybw'\n",
    "  AND start_time >= CURRENT_TIMESTAMP - INTERVAL 1 hour\n",
    "ORDER BY start_time DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2932a506-50b6-4438-882e-8dab80792b33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- simple example\n",
    "SELECT\n",
    "  cluster_id,\n",
    "  driver,\n",
    "  AVG(cpu_user_percent + cpu_system_percent) AS avg_cpu_utilization,\n",
    "  MAX(cpu_user_percent + cpu_system_percent) AS peak_cpu_utilization,\n",
    "  AVG(cpu_wait_percent) AS avg_cpu_wait,\n",
    "  MAX(cpu_wait_percent) AS max_cpu_wait\n",
    "FROM\n",
    "  system.compute.node_timeline\n",
    "WHERE\n",
    "  start_time >= CURRENT_TIMESTAMP - INTERVAL 24 hour\n",
    "GROUP BY\n",
    "  cluster_id,\n",
    "  driver\n",
    "ORDER BY\n",
    "  avg_cpu_utilization DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f57f2232-e7a2-4435-88b5-c5bee15b3898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "WITH base_metrics AS (\n",
    "  SELECT \n",
    "    nt.workspace_id,\n",
    "    nt.cluster_id,\n",
    "    nt.instance_id,\n",
    "    nt.driver,\n",
    "    nt.start_time,\n",
    "    -- CPU Analysis with combined metrics\n",
    "    (nt.cpu_user_percent + nt.cpu_system_percent + nt.cpu_wait_percent) as total_cpu_percent,\n",
    "    nt.cpu_wait_percent,\n",
    "    \n",
    "    -- Memory Analysis\n",
    "    nt.mem_used_percent,\n",
    "    nt.mem_swap_percent,\n",
    "    \n",
    "    -- Network Analysis (converted to MB for readability)\n",
    "    nt.network_received_bytes/1024/1024 as network_received_mb,\n",
    "    nt.network_sent_bytes/1024/1024 as network_sent_mb,\n",
    "    \n",
    "    -- Disk Analysis - extract minimum free space across all mount points\n",
    "    -- This uses element_at to safely access map values\n",
    "    LEAST(\n",
    "      element_at(nt.disk_free_bytes_per_mount_point, '/'),\n",
    "      element_at(nt.disk_free_bytes_per_mount_point, '/local_disk0'),\n",
    "      element_at(nt.disk_free_bytes_per_mount_point, '/var/lib/lxc')\n",
    "    )/1024/1024/1024 as min_disk_free_gb, -- Convert to GB for readability\n",
    "    \n",
    "    -- Cluster context from join\n",
    "    c.cluster_name,\n",
    "    c.worker_node_type,\n",
    "    c.worker_count\n",
    "  FROM system.compute.node_timeline nt\n",
    "  LEFT JOIN system.compute.clusters c \n",
    "    ON nt.cluster_id = c.cluster_id \n",
    "    AND nt.workspace_id = c.workspace_id\n",
    "  WHERE 1=1\n",
    "    -- Time window filter\n",
    "    AND nt.start_time >= CURRENT_TIMESTAMP - INTERVAL 24 hour\n",
    "    -- Optional filters (uncomment and modify as needed)\n",
    "    AND nt.workspace_id = '1444828305810485'\n",
    "    -- AND nt.cluster_id = '1226-175906-bn5rblc1'\n",
    "),\n",
    "\n",
    "aggregated_metrics AS (\n",
    "  SELECT \n",
    "    workspace_id,\n",
    "    cluster_id,\n",
    "    instance_id,\n",
    "    driver,\n",
    "    cluster_name,\n",
    "    worker_node_type,\n",
    "    worker_count,\n",
    "    \n",
    "    -- CPU Metrics\n",
    "    AVG(total_cpu_percent) as avg_cpu_usage,\n",
    "    MAX(total_cpu_percent) as max_cpu_usage,\n",
    "    AVG(cpu_wait_percent) as avg_cpu_wait,\n",
    "    \n",
    "    -- Memory Metrics\n",
    "    AVG(mem_used_percent) as avg_memory_usage,\n",
    "    MAX(mem_used_percent) as max_memory_usage,\n",
    "    MAX(mem_swap_percent) as max_swap_usage,\n",
    "    \n",
    "    -- Network Metrics\n",
    "    AVG(network_received_mb + network_sent_mb) as avg_network_throughput_mb,\n",
    "    MAX(network_received_mb + network_sent_mb) as max_network_throughput_mb,\n",
    "    \n",
    "    -- Disk Metrics\n",
    "    MIN(min_disk_free_gb) as min_disk_free_gb,\n",
    "    \n",
    "    -- Time range context\n",
    "    MIN(start_time) as period_start,\n",
    "    MAX(start_time) as period_end\n",
    "  FROM base_metrics\n",
    "  GROUP BY \n",
    "    workspace_id,\n",
    "    cluster_id,\n",
    "    instance_id,\n",
    "    driver,\n",
    "    cluster_name,\n",
    "    worker_node_type,\n",
    "    worker_count\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  -- Identity and Context\n",
    "  workspace_id,\n",
    "  cluster_name,\n",
    "  cluster_id,\n",
    "  instance_id,\n",
    "  CASE WHEN driver THEN 'Driver' ELSE 'Worker' END as node_type,\n",
    "  worker_node_type,\n",
    "  worker_count,\n",
    "  \n",
    "  -- Performance Metrics (rounded for readability)\n",
    "  ROUND(avg_cpu_usage, 2) as avg_cpu_usage,\n",
    "  ROUND(max_cpu_usage, 2) as max_cpu_usage,\n",
    "  ROUND(avg_cpu_wait, 2) as avg_cpu_wait,\n",
    "  ROUND(avg_memory_usage, 2) as avg_memory_usage,\n",
    "  ROUND(max_memory_usage, 2) as max_memory_usage,\n",
    "  ROUND(avg_network_throughput_mb, 2) as avg_network_mb,\n",
    "  ROUND(min_disk_free_gb, 2) as min_disk_free_gb,\n",
    "  \n",
    "  -- Enhanced Status Indicators with Severity Levels\n",
    "  CASE \n",
    "    WHEN avg_cpu_usage > 80 THEN 'CRITICAL: High sustained CPU usage (' || ROUND(avg_cpu_usage, 1) || '%)'\n",
    "    WHEN max_cpu_usage > 90 THEN 'WARNING: CPU spikes detected (' || ROUND(max_cpu_usage, 1) || '%)'\n",
    "    WHEN avg_cpu_wait > 20 THEN 'WARNING: High I/O wait times (' || ROUND(avg_cpu_wait, 1) || '%)'\n",
    "    ELSE 'OK (CPU avg: ' || ROUND(avg_cpu_usage, 1) || '%)'\n",
    "  END as cpu_status,\n",
    "  \n",
    "  CASE \n",
    "    WHEN avg_memory_usage > 85 THEN 'CRITICAL: Severe memory pressure (' || ROUND(avg_memory_usage, 1) || '%)'\n",
    "    WHEN avg_memory_usage > 75 THEN 'WARNING: High memory usage (' || ROUND(avg_memory_usage, 1) || '%)'\n",
    "    WHEN max_swap_usage > 0 THEN 'WARNING: Memory swapping detected'\n",
    "    ELSE 'OK (Memory avg: ' || ROUND(avg_memory_usage, 1) || '%)'\n",
    "  END as memory_status,\n",
    "  \n",
    "  CASE \n",
    "    WHEN avg_network_throughput_mb > 100 THEN 'WARNING: High network utilization (' || ROUND(avg_network_throughput_mb, 1) || ' MB/s)'\n",
    "    WHEN max_network_throughput_mb > 500 THEN 'WARNING: Network spikes detected (' || ROUND(max_network_throughput_mb, 1) || ' MB/s)'\n",
    "    ELSE 'OK (Network avg: ' || ROUND(avg_network_throughput_mb, 1) || ' MB/s)'\n",
    "  END as network_status,\n",
    "  \n",
    "  -- Added Disk Status\n",
    "  CASE \n",
    "    WHEN min_disk_free_gb < 10 THEN 'CRITICAL: Very low disk space (' || ROUND(min_disk_free_gb, 1) || ' GB free)'\n",
    "    WHEN min_disk_free_gb < 50 THEN 'WARNING: Low disk space (' || ROUND(min_disk_free_gb, 1) || ' GB free)'\n",
    "    ELSE 'OK (Disk space: ' || ROUND(min_disk_free_gb, 1) || ' GB free)'\n",
    "  END as disk_status,\n",
    "  \n",
    "  -- Time Context\n",
    "  period_start as monitoring_start,\n",
    "  period_end as monitoring_end,\n",
    "  \n",
    "  -- Overall Health Score (0-100, lower is worse)\n",
    "  100 - (\n",
    "    CASE \n",
    "      WHEN avg_cpu_usage > 80 THEN 30\n",
    "      WHEN max_cpu_usage > 90 THEN 15\n",
    "      WHEN avg_cpu_wait > 20 THEN 10\n",
    "      ELSE 0\n",
    "    END +\n",
    "    CASE \n",
    "      WHEN avg_memory_usage > 85 THEN 30\n",
    "      WHEN avg_memory_usage > 75 THEN 15\n",
    "      WHEN max_swap_usage > 0 THEN 10\n",
    "      ELSE 0\n",
    "    END +\n",
    "    CASE \n",
    "      WHEN avg_network_throughput_mb > 100 THEN 20\n",
    "      WHEN max_network_throughput_mb > 500 THEN 10\n",
    "      ELSE 0\n",
    "    END +\n",
    "    CASE \n",
    "      WHEN min_disk_free_gb < 10 THEN 20\n",
    "      WHEN min_disk_free_gb < 50 THEN 10\n",
    "      ELSE 0\n",
    "    END\n",
    "  ) as health_score\n",
    "\n",
    "FROM aggregated_metrics\n",
    "WHERE period_start >= CURRENT_TIMESTAMP - INTERVAL 24 hour\n",
    "ORDER BY \n",
    "  -- Prioritize issues by severity\n",
    "  CASE \n",
    "    WHEN avg_cpu_usage > 80 OR avg_memory_usage > 85 OR avg_network_throughput_mb > 100 OR min_disk_free_gb < 10 THEN 1\n",
    "    WHEN max_cpu_usage > 90 OR avg_memory_usage > 75 OR max_network_throughput_mb > 500 OR min_disk_free_gb < 50 THEN 2\n",
    "    ELSE 3\n",
    "  END,\n",
    "  workspace_id,\n",
    "  cluster_name,\n",
    "  driver DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af24e57d-b030-46cc-a336-e31fbb18620e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- What clusters currently have autoscaling turned on with the max workers set to a value higher than 10?\n",
    "with clusters_current as (\n",
    "  SELECT\n",
    "    *,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY cluster_id\n",
    "      ORDER BY\n",
    "        change_time DESC\n",
    "    ) AS row_num\n",
    "  FROM\n",
    "    system.compute.clusters QUALIFY row_num = 1\n",
    ")\n",
    "select\n",
    "  *\n",
    "from\n",
    "  clusters_current\n",
    "where\n",
    "  max_autoscale_workers >= 10\n",
    "  and delete_time is null\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4667900b-cec9-4876-9597-64b21c04b43f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- What clusters currently don’t have auto-termination enabled or their auto-termination timeout longer than two hours?\n",
    "with clusters_current as (\n",
    "  SELECT\n",
    "    *,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY cluster_id\n",
    "      ORDER BY\n",
    "        change_time DESC\n",
    "    ) AS row_num\n",
    "  FROM\n",
    "    system.compute.clusters QUALIFY row_num = 1\n",
    ")\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  clusters_current\n",
    "where\n",
    "  (\n",
    "    auto_termination_minutes is null\n",
    "    or auto_termination_minutes > 120\n",
    "  )\n",
    "  and cluster_name not like 'job-%' -- don't want job clusters\n",
    "  and delete_time is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2bd833d-ade0-4f5e-9aa9-fe23ed82a43e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "system-tables-compute",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "dbrx-de-WrvEAxQj-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
