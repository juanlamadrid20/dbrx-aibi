{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5410aa7-44a1-44f5-a106-bfebd1ba504c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Capture system table descriptions and sample data. \n",
    "Save output and feed to LLM to generate SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d03ef79-53df-46b4-bdb6-4503e14deaaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of system catalog schemas\n",
    "schemas = [\"access\", \"ai\", \"billing\", \"compute\", \"query\", \"serving\", \"storage\", \"lakeflow\", \"information_schema\"]\n",
    "\n",
    "# Function to describe a table and capture 10 sample rows\n",
    "def describe_and_sample(schema, table):\n",
    "    # Describe the table\n",
    "    description = spark.sql(f\"DESCRIBE system.{schema}.{table}\").collect()\n",
    "    \n",
    "    # Capture 10 sample rows\n",
    "    sample_rows = spark.sql(f\"SELECT * FROM system.{schema}.{table} LIMIT 10\").collect()\n",
    "    \n",
    "    return description, sample_rows\n",
    "\n",
    "# Open the file to write the output\n",
    "with open(\"/Volumes/juan_dev/data_eng/data/output.txt\", \"w\") as file:\n",
    "    # Iterate over each schema and table\n",
    "    for schema in schemas:\n",
    "        # Get the list of tables in the schema\n",
    "        tables = spark.sql(f\"SHOW TABLES IN system.{schema}\").select(\"tableName\").rdd.flatMap(lambda x: x).collect()\n",
    "        \n",
    "        for table in tables:\n",
    "            description, sample_rows = describe_and_sample(schema, table)\n",
    "            \n",
    "            # Write the description and sample rows to the file\n",
    "            file.write(f\"Description of {schema}.{table}:\\n\")\n",
    "            for row in description:\n",
    "                file.write(f\"{row}\\n\")\n",
    "            \n",
    "            file.write(f\"\\nSample rows from {schema}.{table}:\\n\")\n",
    "            for row in sample_rows:\n",
    "                file.write(f\"{row}\\n\")\n",
    "            file.write(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a76a0ae-32c9-498c-8e47-862a6089230a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "system_table_descriptions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
